{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from algo_nn import ConvNetClassifier, DenseNetClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of visages matrix -->  (370, 50, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "with open('data/visages.pkl', 'rb') as fh:\n",
    "    visages = pickle.load(fh)\n",
    "\n",
    "with open('data/noms.pkl', 'rb') as fh:\n",
    "    noms = pickle.load(fh)\n",
    "\n",
    "print('Shape of visages matrix --> ', visages.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici nous avons développer un menue permettant de selection quelle algoritm peux etre selcetionner pour affin d'être utiliser pour la reconnaissance facialle.   \n",
    "\n",
    "La boucle while True: permet à l'utilisateur de choisir l'algorithme à utiliser pour la reconnaissance faciale. L'utilisateur est invité à entrer un nombre entre 1 et 4 (ou 5), puis le choix est validé. Si le choix n'est pas valide, l'utilisateur est invité à entrer à nouveau un nombre valide.   \n",
    "Si le choix est inférieur ou égal à 4, cela signifie que l'utilisateur a choisi l'un des premiers quatre algorithmes d'apprentissage automatique pour la reconnaissance faciale. Dans ce cas, les images des visages sont aplaties en une seule dimension, en effet les algorithms de réseaux de neurone n'ont pas besoins d'avoir une image aplatie.   \n",
    "En fonction du choix de l'utilisateur, le programme instancie l'algorithme d'apprentissage automatique correspondant. Si l'utilisateur choisit l'option 1, il utilise la régression logistique, si c'est l'option 2, il utilise les arbres de décision, et ainsi de suite. Chaque algorithme est ensuite entraîné sur les visages et les noms correspondants.   \n",
    "\n",
    "\n",
    "\n",
    "### LogisticRegression(max_iter=1000) :\n",
    "\n",
    "**max_iter :** C'est un paramètre qui définit le nombre maximal d'itérations que l'algorithme de régression logistique effectue lors de l'optimisation. Par défaut, max_iter vaut 100. Comme la convergence n'était pas atteinte après ce nombre d'itérations, On as dessidez de fixez max_iter à une valeur plus élevée, 1000 dans notre cas, on augmente donc le nombre maximal d'itérations, ce qui peut aider à atteindre une meilleure convergence.\n",
    "\n",
    "### DecisionTreeClassifier(random_state=0) :\n",
    "\n",
    "**random_state:** C'est un paramètre qui contrôle la génération de nombres aléatoires. Lorsque on utilise des algorithmes d'apprentissage automatique basés sur des arbres de décision, comme DecisionTreeClassifier, ils peuvent être sensibles à l'initialisation aléatoire, ce qui signifie que chaque exécution du programme peut donner des résultats légèrement différents en raison de la variation des nombres aléatoires. En fixant random_state à une valeur spécifique, comme 0 dans notre cas, on garanti que les résultats seront reproductibles, c'est-à-dire qu'ils seront les mêmes à chaque exécution du programme, tant que on utilise la même valeur de random_state.\n",
    "\n",
    "### KNeighborsClassifier(n_neighbors=4) :\n",
    "\n",
    "**n_neighbors:** C'est un paramètre qui définit le nombre de voisins à prendre en compte lors de la classification d'un nouvel exemple. Dans ce cas, vous avez défini n_neighbors sur 4, ce qui signifie que lors de la prédiction de la classe d'un nouvel exemple, l'algorithme k-NN prendra en compte les 4 exemples les plus proches dans l'espace des caractéristiques pour décider de la classe de l'exemple nouvellement présenté."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visage (370, 50, 50, 3)\n",
      "Labels (370,)\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stygrisse\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 6ms/step - loss: 28.9689 - accuracy: 0.0784\n",
      "Epoch 2/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.8850 - accuracy: 0.0189\n",
      "Epoch 3/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.8142 - accuracy: 0.0811\n",
      "Epoch 4/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6431 - accuracy: 0.1622\n",
      "Epoch 5/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.5595e-06 - accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.5031e-06 - accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.4558e-06 - accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.4271e-06 - accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.4026e-06 - accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.3363e-06 - accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.6136e-06 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Attention, pour la régression logistique, les images doivent être applaties (flattened) en dimension 1\n",
    "N = len(noms)\n",
    "\n",
    "\n",
    "while True:\n",
    "    choix = input(\"Rentrer 1,2,3,4 ou 5 : \\n\" +\"1. algo de logistique regression\\n\" + \"2. algo d'abres de decision\\n\" + \"3. algo de k-NN \\n\" + \"4. Résaux de neuronne Dense\\n\" + \"5. réseaux de neurones convolutionnels\\n\" )\n",
    "    try:\n",
    "        choix = int(choix)\n",
    "    except ValueError:\n",
    "        print('Choix invalide !')\n",
    "    if 1 <= choix <= 5:\n",
    "        break\n",
    "    print('Choix invalide !')\n",
    "\n",
    "if choix <= 4:\n",
    "    visages = visages.reshape(N, -1)\n",
    "\n",
    "if choix == 1 :\n",
    "    algores = LogisticRegression(max_iter=1000)\n",
    "    algores.fit(visages, noms)\n",
    "    titre = \"Regression logistique\"\n",
    "      \n",
    "elif choix == 2 :\n",
    "    algores = DecisionTreeClassifier(random_state=0)\n",
    "    algores.fit(visages, noms)\n",
    "    titre = \"Arbres de decision\"\n",
    "    \n",
    "elif choix == 3 :\n",
    "    algores = KNeighborsClassifier(n_neighbors=4)\n",
    "    algores.fit(visages, noms)\n",
    "    titre = \"k-NN\"\n",
    "\n",
    "elif choix == 4:\n",
    "    algores = DenseNetClassifier(noms)\n",
    "    algores.fit(visages, noms)\n",
    "    titre = \"DenseNet\"\n",
    "\n",
    "elif choix == 5:\n",
    "    algores = ConvNetClassifier(noms)\n",
    "    algores.fit(visages, noms)\n",
    "    titre = \"ConvNet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade_visage = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "camera = cv2.VideoCapture(1) # 0 pour 'built-in' caméra, 1 pour caméra externe\n",
    "user = {}\n",
    "test = \"\\n\"\n",
    "setNom = list(set(noms))\n",
    "for i in range(len(setNom)):\n",
    "    user[i] = setNom[i]\n",
    "    test += str(i) + \".\" + setNom[i] + \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nous avons rajouter dans le code une partie permettant de redimensionner les immages selon l'algorithms utiliser mais aussi une comparaison afin de savoir si oui ou non la personne est admise toujours celon le choix de l'utilsateur demander plus hauts\n",
    "\n",
    "**Redimensionnement de l'image du visage :**\n",
    "\n",
    "Si choix est inférieur à 4, cela signifie que l'algorithme choisi est l'un des quatre premiers (régression logistique, arbres de décision, k-NN ou DenseNet). Dans ce cas, l'image du visage est aplanie (flatten) en un vecteur 1D pour être compatible avec ces algorithmes.\n",
    "Si choix est supérieur ou égal à 4, cela signifie que l'algorithme choisi est l'un des réseaux de neurones convolutifs (DenseNet ou ConvNet). Dans ce cas, l'image du visage est remodelée (reshape) en un tenseur 4D pour être compatible avec ces types d'algorithmes. Les dimensions du tenseur correspondent à la forme attendue par le modèle de réseau de neurones convolutifs (par exemple, 50x50x3 pour une image en couleur de 50x50 pixels).\n",
    "\n",
    "**Prédiction de l'algorithme sélectionné :**\n",
    "\n",
    "Une fois que l'image du visage est prétraitée pour correspondre aux exigences de l'algorithme sélectionné, la méthode predict() de l'algorithme (algores) est appelée avec l'image du visage redimensionnée (visage_redimensionne) en tant qu'entrée. Cela génère une prédiction pour le nom de la personne représentée par l'image du visage.\n",
    "\n",
    "**Traitement des résultats de la prédiction :**\n",
    "\n",
    "En fonction de la prédiction retournée, le code vérifie si le nom prédit (texte[0]) est présent dans une liste nommée admin. Si c'est le cas, cela signifie que la personne est admise, donc le texte de sortie est mis à jour pour inclure \"admis\" à la fin et la couleur du carrer est définie sur vert.\n",
    "Si le nom prédit n'est pas présent dans la liste admin, cela signifie que la personne n'est pas admise, donc le texte de sortie est mis à jour pour inclure \"non admis\" à la fin et la couleur du texte est définie sur magenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "numAdmin = list(map(int, input(\"Qui sont admis : \" + test).split()))\n",
    "admin = []\n",
    "for num in numAdmin:\n",
    "    admin.append(user[num])\n",
    "while True:\n",
    "    \n",
    "    ret, trame = camera.read()\n",
    "    if ret == True:\n",
    "        \n",
    "        gris = cv2.cvtColor(trame, cv2.COLOR_BGR2GRAY)\n",
    "        coordonnees_visage = cascade_visage.detectMultiScale(gris, 1.3, 5)\n",
    "\n",
    "        for (x, y, l, h) in coordonnees_visage:\n",
    "            \n",
    "            visage = trame[y:y + h, x:x + l, :]\n",
    "            visage_redimensionne = cv2.resize(visage, (50, 50))\n",
    "            if choix < 4:\n",
    "                visage_redimensionne = visage_redimensionne.flatten().reshape(1,-1)\n",
    "            elif choix >= 4:\n",
    "                visage_redimensionne = visage_redimensionne.reshape(1, 50, 50, 3)\n",
    "            texte = algores.predict(visage_redimensionne)\n",
    "            \n",
    "            if texte[0] in admin:\n",
    "                data = texte[0] + \" admis\"\n",
    "                col = (0, 255, 0)\n",
    "            else:\n",
    "                col = (255, 0, 0)\n",
    "                data = texte[0] + \" non admis\"\n",
    "            \n",
    "            \n",
    "            cv2.putText(trame, data, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "            cv2.rectangle(trame, (x, y), (x + l, y + l), col, 2)\n",
    "\n",
    "        cv2.imshow(titre, trame)\n",
    "        \n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        print(\"erreur\")\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "camera.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
